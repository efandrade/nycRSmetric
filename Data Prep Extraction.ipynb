{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%qtconsole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Raw Data\n",
    "\n",
    "I load the csv yellow and green taxi data for the month of June 2016 and concatenate the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_green = 'green_tripdata_2016-06.csv'\n",
    "filename_yellow = 'yellow_tripdata_2016-06.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green = pd.read_csv(filename_green, sep=',')\n",
    "df_yellow = pd.read_csv(filename_yellow, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow.rename(str.lower,axis='columns',inplace=True)\n",
    "df_yellow.rename(columns={'tpep_pickup_datetime': 'pep_pickup_datetime','tpep_dropoff_datetime': 'pep_dropoff_datetime'},inplace=True)\n",
    "df_green.rename(str.lower,axis='columns',inplace=True)\n",
    "df_green.rename(columns={'lpep_pickup_datetime': 'pep_pickup_datetime','lpep_dropoff_datetime': 'pep_dropoff_datetime'},inplace=True)\n",
    "df_green.drop(columns={'ehail_fee','trip_type '},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrade/miniconda3/envs/via/lib/python3.7/site-packages/pandas/core/frame.py:6701: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "df = df_yellow.append(df_green)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow is the first 5 entries in the dataset from http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>extra</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>pep_dropoff_datetime</th>\n",
       "      <th>pep_pickup_datetime</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>ratecodeid</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>vendorid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.753979</td>\n",
       "      <td>-73.977463</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-09 21:13:08</td>\n",
       "      <td>2016-06-09 21:06:36</td>\n",
       "      <td>40.760937</td>\n",
       "      <td>-73.983360</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.670242</td>\n",
       "      <td>-73.981636</td>\n",
       "      <td>0.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-09 21:35:11</td>\n",
       "      <td>2016-06-09 21:06:36</td>\n",
       "      <td>40.736668</td>\n",
       "      <td>-73.981720</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.30</td>\n",
       "      <td>5.22</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.742168</td>\n",
       "      <td>-74.004234</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-09 21:13:10</td>\n",
       "      <td>2016-06-09 21:06:36</td>\n",
       "      <td>40.751072</td>\n",
       "      <td>-73.994316</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.36</td>\n",
       "      <td>1.26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.851540</td>\n",
       "      <td>-73.929466</td>\n",
       "      <td>0.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-09 21:36:10</td>\n",
       "      <td>2016-06-09 21:06:36</td>\n",
       "      <td>40.773891</td>\n",
       "      <td>-73.982361</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.30</td>\n",
       "      <td>7.39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.766445</td>\n",
       "      <td>-73.985909</td>\n",
       "      <td>0.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-09 21:23:23</td>\n",
       "      <td>2016-06-09 21:06:36</td>\n",
       "      <td>40.733173</td>\n",
       "      <td>-73.987106</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.76</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropoff_latitude  dropoff_longitude  extra  fare_amount  \\\n",
       "0         40.753979         -73.977463    0.5          6.0   \n",
       "1         40.670242         -73.981636    0.5         22.0   \n",
       "2         40.742168         -74.004234    0.5          6.5   \n",
       "3         40.851540         -73.929466    0.5         26.0   \n",
       "4         40.766445         -73.985909    0.5         13.5   \n",
       "\n",
       "   improvement_surcharge  mta_tax  passenger_count  payment_type  \\\n",
       "0                    0.3      0.5                2             2   \n",
       "1                    0.3      0.5                1             1   \n",
       "2                    0.3      0.5                1             1   \n",
       "3                    0.3      0.5                1             1   \n",
       "4                    0.3      0.5                1             1   \n",
       "\n",
       "  pep_dropoff_datetime  pep_pickup_datetime  pickup_latitude  \\\n",
       "0  2016-06-09 21:13:08  2016-06-09 21:06:36        40.760937   \n",
       "1  2016-06-09 21:35:11  2016-06-09 21:06:36        40.736668   \n",
       "2  2016-06-09 21:13:10  2016-06-09 21:06:36        40.751072   \n",
       "3  2016-06-09 21:36:10  2016-06-09 21:06:36        40.773891   \n",
       "4  2016-06-09 21:23:23  2016-06-09 21:06:36        40.733173   \n",
       "\n",
       "   pickup_longitude  ratecodeid store_and_fwd_flag  tip_amount  tolls_amount  \\\n",
       "0        -73.983360           1                  N        0.00           0.0   \n",
       "1        -73.981720           1                  N        4.00           0.0   \n",
       "2        -73.994316           1                  N        1.56           0.0   \n",
       "3        -73.982361           1                  N        1.00           0.0   \n",
       "4        -73.987106           1                  N        2.96           0.0   \n",
       "\n",
       "   total_amount  trip_distance  vendorid  \n",
       "0          7.30           0.79         2  \n",
       "1         27.30           5.22         2  \n",
       "2          9.36           1.26         2  \n",
       "3         28.30           7.39         2  \n",
       "4         17.76           3.10         2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Shapefiles for Manhattan and Astoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = gpd.read_file('nynta_18d/nynta.shp')\n",
    "nb = nb.to_crs({\"init\": \"epsg:4326\"})\n",
    "astoria = nb.loc[nb['NTAName'] == 'Astoria']\n",
    "astoria_shape = astoria.geometry[astoria.index[0]]\n",
    "boroughs = gpd.read_file('Borough Boundaries/geo_export_0de71584-a1b1-48e3-adda-f106fd662625.shp')\n",
    "manhattan = boroughs.loc[boroughs['boro_name'] == 'Manhattan']\n",
    "manhattan_shape = manhattan.geometry[manhattan.index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astoria Pick Up\n",
    "\n",
    "Now select all the data points that have a pickup location in Astroria. The Area of Astoria is as defined by NYC from the shapefiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "div: 125, mod: 40196\n",
      "loop: 125\r"
     ]
    }
   ],
   "source": [
    "chunk = 100000\n",
    "div = int(df.shape[0]/chunk)\n",
    "mod = int(df.shape[0]%chunk)\n",
    "astoria_df = pd.DataFrame()\n",
    "print('div: ' + str(div) + ', mod: ' +str(mod))\n",
    "\n",
    "for i in range(div+1):\n",
    "    lower = i*chunk\n",
    "    upper = (i+1)*chunk\n",
    "    if i == div:\n",
    "        upper = lower + mod\n",
    "    myrange = range(lower,upper)\n",
    "    temp = df.iloc[myrange]\n",
    "    geometry = [Point(xy) for xy in zip(temp.pickup_longitude, temp.pickup_latitude)]\n",
    "    astoria_df = astoria_df.append(temp.loc[[astoria_shape.contains(x) for x in geometry]])\n",
    "    print('loop: ' + str(i),end='\\r')\n",
    "    #adf_y.to_csv('test.csv')\n",
    "    #adf_y.to_csv('astoria data/astoria_yellow_' + str(i) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "astoria_df.to_csv('2016-06 astoria pickup.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Astoria Dropoff and Manhattan Dropoff\n",
    "\n",
    "Now having a set of data that corresponds to all the pickups originating in Astoria, I select the subset of data where the dropoff location was in Astoria and also get the subset where the dropoff location was in Manhattan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = [Point(xy) for xy in zip(astoria_df.dropoff_longitude, astoria_df.dropoff_latitude)]\n",
    "astoria_astoria_df = astoria_df.loc[[astoria_shape.contains(x) for x in geometry]]\n",
    "astoria_manhattan_df = astoria_df.loc[[manhattan_shape.contains(x) for x in geometry]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "astoria_astoria_df.to_csv('2016-06 astoria to astoria.csv')\n",
    "astoria_manhattan_df.to_csv('2016-06 astoria to manhattan.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manhattan Pick Up\n",
    "\n",
    "Now I again take the original dataset for June 2016 and select all the trips where the pickup location originated in Manhattan. As most taxi rides took place in Manhattan I had to parallelize the sorting using 3 processing cores. Using more cores maxed out my available RAM so I was limited to 3 cores. Furthermore, I saved subsets of my desired dataset directly to the hard drive in order to save RAM memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 10000\n",
    "div = int(df.shape[0]/chunk)\n",
    "mod = int(df.shape[0]%chunk)\n",
    "print('div: ' + str(div) + ', mod: ' +str(mod))\n",
    "\n",
    "def processInput(i):\n",
    "    lower = i*chunk\n",
    "    upper = (i+1)*chunk\n",
    "    if i == div:\n",
    "        upper = lower + mod\n",
    "    myrange = range(lower,upper)\n",
    "    temp = df.iloc[myrange]\n",
    "    geometry = [Point(xy) for xy in zip(temp.pickup_longitude, temp.pickup_latitude)]\n",
    "    temp = temp.loc[[manhattan_shape.contains(x) for x in geometry]]\n",
    "    temp.to_csv('manhattan/pickup/manhattan_pickup_' + str(i) + '.csv')\n",
    " \n",
    "num_cores = 3\n",
    "     \n",
    "Parallel(n_jobs=num_cores)(delayed(processInput)(i) for i in range(div+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the above finished which took hours to complete, I loaded each of the csv files and created a dataframe in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#removing unnamed columns\n",
    "df.loc[:, ~df.columns.str.contains('^Unnamed')]manhattan_df = pd.DataFrame()\n",
    "for i in range(div+1):\n",
    "    print('csv file: ' + str(i),end='\\r')\n",
    "    manhattan_df =  manhattan_df.append(pd.read_csv('manhattan/pickup/manhattan_pickup_' + str(i) + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_df.to_csv('data/2016-06 manhattan pickup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_df = pd.read_csv('data/2016-06 manhattan pickup.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manhattan Dropoff\n",
    "\n",
    "With the subset of data corresponding to pickups in Manhattan, I then found the subset of data with the dropoff point being in Manhattan. Again, due to the number of data points I had to parallelize the sorting with 3 processing cores and save shunks of data to the hard drive. And again this took hours to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 10000\n",
    "div = int(manhattan_df.shape[0]/chunk)\n",
    "mod = int(manhattan_df.shape[0]%chunk)\n",
    "print('div: ' + str(div) + ', mod: ' +str(mod))\n",
    "\n",
    "def processInput(i):\n",
    "    lower = i*chunk\n",
    "    upper = (i+1)*chunk\n",
    "    if i == div:\n",
    "        upper = lower + mod\n",
    "    myrange = range(lower,upper)\n",
    "    temp = manhattan_df.iloc[myrange]\n",
    "    geometry = [Point(xy) for xy in zip(temp.dropoff_longitude, temp.dropoff_latitude)]\n",
    "    temp = temp.loc[[manhattan_shape.contains(x) for x in geometry]]\n",
    "    temp.to_csv('manhattan/pickup_dropoff/manhattan_pickup_dropoff_' + str(i) + '.csv')\n",
    " \n",
    "num_cores = 3\n",
    "     \n",
    "Parallel(n_jobs=num_cores)(delayed(processInput)(i) for i in range(div+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, after the above finished, I loaded each of the csv files and created a dataframe in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file: 1048\r"
     ]
    }
   ],
   "source": [
    "manhattan_manhattan_df = pd.DataFrame()\n",
    "for i in range(div+1):\n",
    "    print('csv file: ' + str(i),end='\\r')\n",
    "    manhattan_manhattan_df =  manhattan_manhattan_df.append(pd.read_csv('manhattan/pickup_dropoff/manhattan_pickup_dropoff_' + str(i) + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_manhattan_df.to_csv('data/2016-06 manhattan to manhattan.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Astoria Dropoff\n",
    "\n",
    "Using the set of data that corresponds to all the pickups originating in Manhattan, I select the subset of data where the dropoff location was in Astoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = [Point(xy) for xy in zip(manhattan_df.dropoff_longitude, manhattan_df.dropoff_latitude)]\n",
    "manhattan_astoria_df = manhattan_df.loc[[astoria_shape.contains(x) for x in geometry]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_astoria_df.to_csv('2016-06 manhattan to astoria.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
